{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Londonn Smart Meters (Simulation with TensorFlow/Keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics \n",
    "# Evaluation metrics that can be returned by clients or aggregated by the server during the federated learning process.\n",
    "\n",
    "\n",
    "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth # to enable TensorFlow to grow its GPU memory allocation dynamically\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Change NUM_CLIENTS to 30 for FL with Stacked LSTM Model where number of clients 30 and number of meters are 100\n",
    "VERBOSE = 0\n",
    "NUM_CLIENTS = 100\n",
    "# Define number of meters to be used in the project \n",
    "NUM_OF_METERS = 100 \n",
    "# write hourly_data['LCLid'].max() to include all meters available in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, return_sequences=True, input_shape=(None, 1))) # This adds an LSTM layer with 50 neurons (units)\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(15, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(10, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(5))   # 4th LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, x_train, y_train, x_val, y_val) -> None:\n",
    "        # Create model\n",
    "        self.model = get_model()\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train parameters on the locally held training set.\"\"\"\n",
    "\n",
    "        # Update local model parameters\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "        # Get hyperparameters for this round\n",
    "        #batch_size: int = config[\"batch_size\"]\n",
    "        #epochs: int = config[\"local_epochs\"]\n",
    "\n",
    "        # Train the model using hyperparameters from config\n",
    "        history = self.model.fit(\n",
    "            self.x_train,\n",
    "            self.y_train,\n",
    "            batch_size = 512,\n",
    "            epochs = 10,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Return updated model parameters and results\n",
    "        parameters_prime = self.model.get_weights()\n",
    "        num_examples_train = len(self.x_train)\n",
    "        results = {\n",
    "            \"loss\": history.history[\"loss\"][0],\n",
    "            \"accuracy\": history.history[\"mean_absolute_error\"][0]\n",
    "        }\n",
    "        return parameters_prime, num_examples_train, results\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate parameters on the locally held test set.\"\"\"\n",
    "\n",
    "        # Update local model with global parameters\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "        # Get config values\n",
    "        #steps: int = config[\"val_steps\"]\n",
    "\n",
    "        # Evaluate global model parameters on the local test data and return results\n",
    "        results = self.model.evaluate(self.x_val, self.y_val, 32)#, steps=steps)\n",
    "        num_examples_test = len(self.x_val)\n",
    "        return results[0], num_examples_test, {\"accuracy\": results[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use preprocessed dataset with only LCLid (unique consumer ID) and KWH/hh (per hour) (energy consumption per hour) columns replace the following cell with the code snipped below:\n",
    "\n",
    "hourly_data = pd.read_csv(\"Preprocessed_data2013_2.csv\", dtype={'LCLid': np.int16, 'KWH/hh (per hour) ': np.float64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53148577 entries, 0 to 53148576\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   LCLid               int16  \n",
      " 1   dayoftheyear        int16  \n",
      " 2   hour                int8   \n",
      " 3   is_weekend          int8   \n",
      " 4   KWH/hh (per hour)   float64\n",
      "dtypes: float64(1), int16(2), int8(2)\n",
      "memory usage: 709.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "dataset = pd.read_csv(\"Preprocessed_data.csv\", dtype={'LCLid': np.int16, 'KWH/hh (per hour) ': np.float64, 'dayoftheyear': np.int16,\n",
    "       'hour': np.int8, 'is_weekend': np.int8})\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validate(data):\n",
    "\n",
    "    # Initialize train and validation \n",
    "    train_l = []\n",
    "    val_l = []\n",
    "\n",
    "    # Counter of elements inside the partition \n",
    "    part_counter = 0\n",
    "\n",
    "    # Number of meters that each of the clients will have (note: last client will have more or equal than others)\n",
    "    part_size = int(NUM_OF_METERS / NUM_CLIENTS)\n",
    "\n",
    "    # Initialize counter for the number of partitions \n",
    "    part_id = 0\n",
    "\n",
    "    for i in range(0, NUM_OF_METERS):\n",
    "\n",
    "        # Get the data for current meter\n",
    "        tmp_data = data[data['LCLid'] == i]\n",
    "\n",
    "        # Split index between train and validate\n",
    "        val_split = int(len(tmp_data) * 0.8)\n",
    "        # Split index between validate and test\n",
    "        test_split = int(len(tmp_data) * 0.9)\n",
    "\n",
    "        # Set initial splits for current meter\n",
    "        train_ = tmp_data[:val_split]\n",
    "        vali_ = tmp_data[val_split:test_split]\n",
    "        test_ = tmp_data[test_split:]\n",
    "\n",
    "        # Concatanate the test data \n",
    "        if (i > 0):\n",
    "            test = pd.concat([test, test_], ignore_index=True)\n",
    "        else:\n",
    "            test = test_\n",
    "\n",
    "        # Concatanate train and validation inside current partition  \n",
    "        if (part_counter > 0):\n",
    "            train = pd.concat([train, train_], ignore_index=True)\n",
    "            valid = pd.concat([valid, vali_], ignore_index=True)\n",
    "        else: \n",
    "            train = train_\n",
    "            valid = vali_\n",
    "            \n",
    "        # Increase the counter inside current partition \n",
    "        part_counter += 1\n",
    "        if (part_counter >= part_size) and (part_id < NUM_CLIENTS - 1):\n",
    "\n",
    "            # Reset counter inside current partition for the next one \n",
    "            part_counter = 0\n",
    "\n",
    "            # Append validation and train data to the partition they belong to   \n",
    "            train_l.append(train.reset_index(drop=True))\n",
    "            val_l.append(valid.reset_index(drop=True))\n",
    "\n",
    "            # Increase partition counter\n",
    "            part_id += 1\n",
    "\n",
    "            # Reset values \n",
    "            train = pd.DataFrame()\n",
    "            valid = pd.DataFrame()\n",
    "\n",
    "    if (part_counter != 0):\n",
    "        \n",
    "        # Append train and validation to the last partition\n",
    "        train_l.append(train)\n",
    "        val_l.append(valid)\n",
    "\n",
    "    return {\"train\": train_l, \"test\": test.reset_index(drop=True), \"validation\": val_l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_fn(partition):\n",
    "    \"\"\"Return a function to construct a client.\n",
    "\n",
    "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
    "    the strategy to participate.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
    "        \n",
    "        # Extract partition for client with id = cid\n",
    "        trainset = partition[\"train\"][int(cid)]\n",
    "        valset = partition[\"validation\"][int(cid)] \n",
    "\n",
    "        # Split into features and targets and transform into tensors \n",
    "        x_train_tensor = tf.convert_to_tensor(np.asarray(trainset.drop(columns=['KWH/hh (per hour) '])))\n",
    "        y_train_tensor = tf.convert_to_tensor(np.asarray(trainset['KWH/hh (per hour) ']))\n",
    "        x_val_tensor = tf.convert_to_tensor(np.asarray(valset.drop(columns=['KWH/hh (per hour) '])))\n",
    "        y_val_tensor = tf.convert_to_tensor(np.asarray(valset['KWH/hh (per hour) ']))\n",
    "\n",
    "        # Create and return client\n",
    "        return FlowerClient(x_train_tensor, y_train_tensor, x_val_tensor, y_val_tensor).to_client()\n",
    "\n",
    "    return client_fn\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
    "    the client's evaluate() method.\"\"\"\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "def get_evaluate_fn(testset):\n",
    "    \"\"\"Return an evaluation function for server-side (i.e. centralised) evaluation.\"\"\"\n",
    "\n",
    "    # The `evaluate` function will be called after every round by the strategy\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ):\n",
    "        model = get_model()  # Construct the model\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        results = model.evaluate(tf.convert_to_tensor(np.asarray(testset.drop(columns=['KWH/hh (per hour) ']))), \n",
    "                                 tf.convert_to_tensor(np.asarray(testset['KWH/hh (per hour) '])), \n",
    "                                 verbose=VERBOSE)\n",
    "        return results[0], {\"accuracy\": results[1]}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
    "# Enable GPU growth in your main process\n",
    "enable_tf_gpu_growth()\n",
    "\n",
    "df_dataset = train_test_validate(dataset)\n",
    "\n",
    "# Get the whole test set for centralised evaluation\n",
    "centralized_testset = df_dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n",
      "2024-07-11 06:27:30,856\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 6943960269.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 2147483648.0, 'CPU': 10.0, 'node:__internal_head__': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 8.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:27:34.017080: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:27:34.017131: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:27:34.017143: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:27:34.017175: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:27:34.017197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "2024-07-11 06:27:34.746004: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-07-11 06:27:34.746035: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-07-11 06:27:34.746046: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-07-11 06:27:34.746075: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-11 06:27:34.746090: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-07-11 06:27:36.180732: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.176924467086792, {'accuracy': 0.8664068579673767}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 100)\n",
      "\u001b[36m(ClientAppActor pid=16467)\u001b[0m 2024-07-11 06:28:18.188586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.466597557067871, {'accuracy': 0.6424623131752014}, 759.7833250830008)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/44 [..............................] - ETA: 1:47 - loss: 0.3099 - mean_absolute_error: 0.5409\n",
      " 2/44 [>.............................] - ETA: 2s - loss: 0.2776 - mean_absolute_error: 0.5038  \n",
      " 3/44 [=>............................] - ETA: 6s - loss: 0.2707 - mean_absolute_error: 0.4972\n",
      " 5/44 [==>...........................] - ETA: 4s - loss: 0.2529 - mean_absolute_error: 0.4778\n",
      " 6/44 [===>..........................] - ETA: 3s - loss: 0.2550 - mean_absolute_error: 0.4809\n",
      " 8/44 [====>.........................] - ETA: 3s - loss: 0.2516 - mean_absolute_error: 0.4763\n",
      " 9/44 [=====>........................] - ETA: 3s - loss: 0.2547 - mean_absolute_error: 0.4793\n",
      "11/44 [======>.......................] - ETA: 2s - loss: 0.2539 - mean_absolute_error: 0.4779\n",
      "16/44 [=========>....................] - ETA: 1s - loss: 0.2549 - mean_absolute_error: 0.4790\n",
      "26/44 [================>.............] - ETA: 0s - loss: 0.2521 - mean_absolute_error: 0.4759\n",
      "36/44 [=======================>......] - ETA: 0s - loss: 0.2514 - mean_absolute_error: 0.4750\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.2506 - mean_absolute_error: 0.4741\n",
      "44/44 [==============================] - 4s 37ms/step - loss: 0.2514 - mean_absolute_error: 0.4750\n",
      " 1/44 [..............................] - ETA: 1:29 - loss: 0.0274 - mean_absolute_error: 0.1245\n",
      " 2/44 [>.............................] - ETA: 5s - loss: 0.0281 - mean_absolute_error: 0.1237  \n",
      " 3/44 [=>............................] - ETA: 4s - loss: 0.0744 - mean_absolute_error: 0.1691\n",
      " 4/44 [=>............................] - ETA: 4s - loss: 0.1182 - mean_absolute_error: 0.2332\n",
      " 7/44 [===>..........................] - ETA: 3s - loss: 0.1465 - mean_absolute_error: 0.2573\n",
      " 8/44 [====>.........................] - ETA: 3s - loss: 0.1495 - mean_absolute_error: 0.2580\n",
      "12/44 [=======>......................] - ETA: 2s - loss: 0.2135 - mean_absolute_error: 0.2818\n",
      "17/44 [==========>...................] - ETA: 1s - loss: 0.2195 - mean_absolute_error: 0.2869\n",
      "27/44 [=================>............] - ETA: 0s - loss: 0.2180 - mean_absolute_error: 0.2880\n",
      "37/44 [========================>.....] - ETA: 0s - loss: 0.2235 - mean_absolute_error: 0.3017\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.2302 - mean_absolute_error: 0.3059\n",
      "44/44 [==============================] - 4s 36ms/step - loss: 0.2264 - mean_absolute_error: 0.3031\n",
      " 1/44 [..............................] - ETA: 1:36 - loss: 0.1550 - mean_absolute_error: 0.3403\n",
      " 2/44 [>.............................] - ETA: 4s - loss: 0.1251 - mean_absolute_error: 0.3122  \n",
      " 3/44 [=>............................] - ETA: 4s - loss: 0.1224 - mean_absolute_error: 0.3081\n",
      " 5/44 [==>...........................] - ETA: 4s - loss: 0.1033 - mean_absolute_error: 0.2774\n",
      " 6/44 [===>..........................] - ETA: 3s - loss: 0.1070 - mean_absolute_error: 0.2850\n",
      " 8/44 [====>.........................] - ETA: 3s - loss: 0.1103 - mean_absolute_error: 0.2912\n",
      "13/44 [=======>......................] - ETA: 1s - loss: 0.1055 - mean_absolute_error: 0.2828\n",
      "18/44 [===========>..................] - ETA: 1s - loss: 0.1339 - mean_absolute_error: 0.3190\n",
      "21/44 [=============>................] - ETA: 1s - loss: 0.1333 - mean_absolute_error: 0.3189\n",
      "28/44 [==================>...........] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.3148\n",
      "37/44 [========================>.....] - ETA: 0s - loss: 0.1265 - mean_absolute_error: 0.3126\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.3081\n",
      "44/44 [==============================] - 4s 35ms/step - loss: 0.1229 - mean_absolute_error: 0.3075\n",
      " 1/44 [..............................] - ETA: 1:47 - loss: 0.1810 - mean_absolute_error: 0.3942\n",
      " 2/44 [>.............................] - ETA: 6s - loss: 0.2287 - mean_absolute_error: 0.4008  \n",
      " 3/44 [=>............................] - ETA: 5s - loss: 0.2551 - mean_absolute_error: 0.3916\n",
      " 4/44 [=>............................] - ETA: 5s - loss: 0.2281 - mean_absolute_error: 0.3559\n",
      " 5/44 [==>...........................] - ETA: 4s - loss: 0.2291 - mean_absolute_error: 0.3522\n",
      " 8/44 [====>.........................] - ETA: 3s - loss: 0.2316 - mean_absolute_error: 0.3594\n",
      "10/44 [=====>........................] - ETA: 2s - loss: 0.2084 - mean_absolute_error: 0.3459\n",
      "14/44 [========>.....................] - ETA: 1s - loss: 0.2440 - mean_absolute_error: 0.3578\n",
      "18/44 [===========>..................] - ETA: 1s - loss: 0.2294 - mean_absolute_error: 0.3532\n",
      "26/44 [================>.............] - ETA: 0s - loss: 0.2412 - mean_absolute_error: 0.3670\n",
      "36/44 [=======================>......] - ETA: 0s - loss: 0.2402 - mean_absolute_error: 0.3616\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.2341 - mean_absolute_error: 0.3538\n",
      "44/44 [==============================] - 4s 41ms/step - loss: 0.2322 - mean_absolute_error: 0.3537\n",
      " 1/44 [..............................] - ETA: 1:51 - loss: 0.1874 - mean_absolute_error: 0.3948\n",
      " 2/44 [>.............................] - ETA: 4s - loss: 0.1494 - mean_absolute_error: 0.3517  \n",
      " 3/44 [=>............................] - ETA: 5s - loss: 0.1274 - mean_absolute_error: 0.3162\n",
      " 4/44 [=>............................] - ETA: 4s - loss: 0.1140 - mean_absolute_error: 0.2913\n",
      " 6/44 [===>..........................] - ETA: 3s - loss: 0.1187 - mean_absolute_error: 0.2976\n",
      "10/44 [=====>........................] - ETA: 2s - loss: 0.1209 - mean_absolute_error: 0.3032\n",
      "17/44 [==========>...................] - ETA: 1s - loss: 0.1264 - mean_absolute_error: 0.2993\n",
      "20/44 [============>.................] - ETA: 1s - loss: 0.1231 - mean_absolute_error: 0.2962\n",
      "22/44 [==============>...............] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2932\n",
      "32/44 [====================>.........] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2921\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2919\n",
      "44/44 [==============================] - 4s 35ms/step - loss: 0.1192 - mean_absolute_error: 0.2915\n",
      " 1/44 [..............................] - ETA: 1:58 - loss: 0.1341 - mean_absolute_error: 0.3051\n",
      " 2/44 [>.............................] - ETA: 5s - loss: 0.0987 - mean_absolute_error: 0.2659  \n",
      " 4/44 [=>............................] - ETA: 5s - loss: 0.1376 - mean_absolute_error: 0.2866\n",
      " 6/44 [===>..........................] - ETA: 3s - loss: 0.1291 - mean_absolute_error: 0.2760\n",
      "12/44 [=======>......................] - ETA: 1s - loss: 0.1285 - mean_absolute_error: 0.2728\n",
      "18/44 [===========>..................] - ETA: 1s - loss: 0.1300 - mean_absolute_error: 0.2712\n",
      "25/44 [================>.............] - ETA: 0s - loss: 0.1310 - mean_absolute_error: 0.2694\n",
      "35/44 [======================>.......] - ETA: 0s - loss: 0.1309 - mean_absolute_error: 0.2683\n",
      "40/44 [==========================>...] - ETA: 0s - loss: 0.1294 - mean_absolute_error: 0.2678\n",
      "44/44 [==============================] - 4s 33ms/step - loss: 0.1274 - mean_absolute_error: 0.2674\n",
      " 1/44 [..............................] - ETA: 1:35 - loss: 0.1902 - mean_absolute_error: 0.3695\n",
      " 2/44 [>.............................] - ETA: 5s - loss: 0.2022 - mean_absolute_error: 0.3966  \n",
      " 3/44 [=>............................] - ETA: 4s - loss: 0.2040 - mean_absolute_error: 0.4057\n",
      " 5/44 [==>...........................] - ETA: 3s - loss: 0.2017 - mean_absolute_error: 0.3862\n",
      " 7/44 [===>..........................] - ETA: 3s - loss: 0.2027 - mean_absolute_error: 0.3953\n",
      " 9/44 [=====>........................] - ETA: 2s - loss: 0.2050 - mean_absolute_error: 0.3990\n",
      "11/44 [======>.......................] - ETA: 2s - loss: 0.2051 - mean_absolute_error: 0.4012\n",
      "14/44 [========>.....................] - ETA: 1s - loss: 0.2029 - mean_absolute_error: 0.3998\n",
      "18/44 [===========>..................] - ETA: 1s - loss: 0.2039 - mean_absolute_error: 0.4015\n",
      "25/44 [================>.............] - ETA: 0s - loss: 0.2034 - mean_absolute_error: 0.3975\n",
      "37/44 [========================>.....] - ETA: 0s - loss: 0.1997 - mean_absolute_error: 0.3939\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.1981 - mean_absolute_error: 0.3936\n",
      "44/44 [==============================] - 4s 38ms/step - loss: 0.1982 - mean_absolute_error: 0.3938\n",
      " 1/33 [..............................] - ETA: 1:14 - loss: 1.0991 - mean_absolute_error: 0.6476\n",
      " 2/33 [>.............................] - ETA: 3s - loss: 0.5704 - mean_absolute_error: 0.4107  \n",
      " 3/33 [=>............................] - ETA: 2s - loss: 0.8167 - mean_absolute_error: 0.5430\n",
      " 4/33 [==>...........................] - ETA: 2s - loss: 0.7397 - mean_absolute_error: 0.5232\n",
      " 5/33 [===>..........................] - ETA: 2s - loss: 0.6833 - mean_absolute_error: 0.5017\n",
      " 7/33 [=====>........................] - ETA: 2s - loss: 0.5755 - mean_absolute_error: 0.4697\n",
      " 9/33 [=======>......................] - ETA: 2s - loss: 0.5107 - mean_absolute_error: 0.4457\n",
      "14/33 [===========>..................] - ETA: 1s - loss: 0.3629 - mean_absolute_error: 0.3724\n",
      "20/33 [=================>............] - ETA: 0s - loss: 0.3361 - mean_absolute_error: 0.3617\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.2820 - mean_absolute_error: 0.3377\n",
      "33/33 [==============================] - 4s 52ms/step - loss: 0.2984 - mean_absolute_error: 0.3463\n",
      " 1/44 [..............................] - ETA: 1:40 - loss: 0.1424 - mean_absolute_error: 0.2996\n",
      " 2/44 [>.............................] - ETA: 6s - loss: 0.1290 - mean_absolute_error: 0.2965  \n",
      " 3/44 [=>............................] - ETA: 7s - loss: 0.1843 - mean_absolute_error: 0.3058\n",
      " 4/44 [=>............................] - ETA: 6s - loss: 0.2494 - mean_absolute_error: 0.3518\n",
      " 8/44 [====>.........................] - ETA: 3s - loss: 0.2099 - mean_absolute_error: 0.3343\n",
      "13/44 [=======>......................] - ETA: 1s - loss: 0.2687 - mean_absolute_error: 0.3627\n",
      "18/44 [===========>..................] - ETA: 1s - loss: 0.2355 - mean_absolute_error: 0.3460\n",
      "26/44 [================>.............] - ETA: 0s - loss: 0.2450 - mean_absolute_error: 0.3476\n",
      "30/44 [===================>..........] - ETA: 0s - loss: 0.2773 - mean_absolute_error: 0.3595\n",
      "39/44 [=========================>....] - ETA: 0s - loss: 0.2868 - mean_absolute_error: 0.3646\n",
      "44/44 [==============================] - 4s 36ms/step - loss: 0.2735 - mean_absolute_error: 0.3584\n",
      " 1/44 [..............................] - ETA: 1:45 - loss: 0.2528 - mean_absolute_error: 0.4111\n",
      " 2/44 [>.............................] - ETA: 7s - loss: 0.2206 - mean_absolute_error: 0.3499  \n",
      " 4/44 [=>............................] - ETA: 3s - loss: 0.7792 - mean_absolute_error: 0.6153\n",
      " 5/44 [==>...........................] - ETA: 3s - loss: 0.8012 - mean_absolute_error: 0.6309\n",
      " 7/44 [===>..........................] - ETA: 2s - loss: 0.6273 - mean_absolute_error: 0.5462\n",
      "11/44 [======>.......................] - ETA: 2s - loss: 0.5015 - mean_absolute_error: 0.4862\n",
      "17/44 [==========>...................] - ETA: 1s - loss: 0.6184 - mean_absolute_error: 0.5370\n",
      "27/44 [=================>............] - ETA: 0s - loss: 0.6682 - mean_absolute_error: 0.5493\n",
      "38/44 [========================>.....] - ETA: 0s - loss: 0.7313 - mean_absolute_error: 0.5832\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.6891 - mean_absolute_error: 0.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 4s 36ms/step - loss: 0.6881 - mean_absolute_error: 0.5692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.5577837228775024, {'accuracy': 0.643508791923523}, 2246.0741741250094)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/44 [..............................] - ETA: 4:08 - loss: 0.2146 - mean_absolute_error: 0.3084\n",
      " 2/44 [>.............................] - ETA: 16s - loss: 0.1313 - mean_absolute_error: 0.2437 \n",
      " 3/44 [=>............................] - ETA: 18s - loss: 0.2234 - mean_absolute_error: 0.3175\n",
      " 4/44 [=>............................] - ETA: 15s - loss: 0.1947 - mean_absolute_error: 0.3011\n",
      " 5/44 [==>...........................] - ETA: 12s - loss: 0.3012 - mean_absolute_error: 0.3595\n",
      " 6/44 [===>..........................] - ETA: 11s - loss: 0.4279 - mean_absolute_error: 0.4049\n",
      " 7/44 [===>..........................] - ETA: 10s - loss: 0.3710 - mean_absolute_error: 0.3652\n",
      "11/44 [======>.......................] - ETA: 6s - loss: 0.2955 - mean_absolute_error: 0.3254\n",
      "14/44 [========>.....................] - ETA: 4s - loss: 0.3830 - mean_absolute_error: 0.3773\n",
      "16/44 [=========>....................] - ETA: 4s - loss: 0.3770 - mean_absolute_error: 0.3721\n",
      "17/44 [==========>...................] - ETA: 4s - loss: 0.3569 - mean_absolute_error: 0.3570\n",
      "19/44 [===========>..................] - ETA: 3s - loss: 0.3218 - mean_absolute_error: 0.3317\n",
      "20/44 [============>.................] - ETA: 3s - loss: 0.3186 - mean_absolute_error: 0.3350\n",
      "22/44 [==============>...............] - ETA: 2s - loss: 0.3298 - mean_absolute_error: 0.3457\n",
      "24/44 [===============>..............] - ETA: 2s - loss: 0.3162 - mean_absolute_error: 0.3375\n",
      "25/44 [================>.............] - ETA: 2s - loss: 0.3087 - mean_absolute_error: 0.3322\n",
      "28/44 [==================>...........] - ETA: 1s - loss: 0.2963 - mean_absolute_error: 0.3280\n",
      "32/44 [====================>.........] - ETA: 1s - loss: 0.2994 - mean_absolute_error: 0.3290\n",
      "36/44 [=======================>......] - ETA: 0s - loss: 0.2857 - mean_absolute_error: 0.3233\n",
      "38/44 [========================>.....] - ETA: 0s - loss: 0.3131 - mean_absolute_error: 0.3390\n",
      "39/44 [=========================>....] - ETA: 0s - loss: 0.3063 - mean_absolute_error: 0.3345\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3083 - mean_absolute_error: 0.3346\n",
      "44/44 [==============================] - 11s 115ms/step - loss: 0.3074 - mean_absolute_error: 0.3342\n",
      " 1/44 [..............................] - ETA: 5:06 - loss: 0.3830 - mean_absolute_error: 0.4707\n",
      " 2/44 [>.............................] - ETA: 28s - loss: 0.4180 - mean_absolute_error: 0.4695 \n",
      " 3/44 [=>............................] - ETA: 19s - loss: 0.3978 - mean_absolute_error: 0.4704\n",
      " 4/44 [=>............................] - ETA: 14s - loss: 0.4509 - mean_absolute_error: 0.4785\n",
      " 5/44 [==>...........................] - ETA: 12s - loss: 0.6053 - mean_absolute_error: 0.5255\n",
      " 6/44 [===>..........................] - ETA: 10s - loss: 0.5510 - mean_absolute_error: 0.5036\n",
      " 8/44 [====>.........................] - ETA: 7s - loss: 0.4372 - mean_absolute_error: 0.4398\n",
      "18/44 [===========>..................] - ETA: 2s - loss: 0.2638 - mean_absolute_error: 0.3429\n",
      "26/44 [================>.............] - ETA: 1s - loss: 0.2574 - mean_absolute_error: 0.3407\n",
      "31/44 [====================>.........] - ETA: 0s - loss: 0.3659 - mean_absolute_error: 0.3889\n",
      "34/44 [======================>.......] - ETA: 0s - loss: 0.3744 - mean_absolute_error: 0.3988\n",
      "35/44 [======================>.......] - ETA: 0s - loss: 0.3658 - mean_absolute_error: 0.3944\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4217 - mean_absolute_error: 0.4246\n",
      "44/44 [==============================] - 11s 84ms/step - loss: 0.4133 - mean_absolute_error: 0.4198\n",
      " 1/44 [..............................] - ETA: 3:27 - loss: 0.1301 - mean_absolute_error: 0.2850\n",
      " 2/44 [>.............................] - ETA: 9s - loss: 0.1672 - mean_absolute_error: 0.2988  \n",
      " 3/44 [=>............................] - ETA: 14s - loss: 0.1878 - mean_absolute_error: 0.3044\n",
      " 4/44 [=>............................] - ETA: 13s - loss: 0.2596 - mean_absolute_error: 0.3448\n",
      " 5/44 [==>...........................] - ETA: 11s - loss: 0.2796 - mean_absolute_error: 0.3660\n",
      " 6/44 [===>..........................] - ETA: 11s - loss: 0.2774 - mean_absolute_error: 0.3658\n",
      "11/44 [======>.......................] - ETA: 5s - loss: 0.2419 - mean_absolute_error: 0.3408 \n",
      "12/44 [=======>......................] - ETA: 5s - loss: 0.2470 - mean_absolute_error: 0.3447\n",
      "16/44 [=========>....................] - ETA: 3s - loss: 0.2579 - mean_absolute_error: 0.3460\n",
      "20/44 [============>.................] - ETA: 2s - loss: 0.2624 - mean_absolute_error: 0.3501\n",
      "21/44 [=============>................] - ETA: 2s - loss: 0.2862 - mean_absolute_error: 0.3608\n",
      "22/44 [==============>...............] - ETA: 2s - loss: 0.2871 - mean_absolute_error: 0.3600\n",
      "24/44 [===============>..............] - ETA: 2s - loss: 0.2776 - mean_absolute_error: 0.3560\n",
      "26/44 [================>.............] - ETA: 1s - loss: 0.2636 - mean_absolute_error: 0.3454\n",
      "31/44 [====================>.........] - ETA: 1s - loss: 0.2944 - mean_absolute_error: 0.3586\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.2896 - mean_absolute_error: 0.3533\n",
      "44/44 [==============================] - 8s 83ms/step - loss: 0.2857 - mean_absolute_error: 0.3522\n",
      " 1/44 [..............................] - ETA: 3:39 - loss: 0.0870 - mean_absolute_error: 0.2388\n",
      " 2/44 [>.............................] - ETA: 10s - loss: 0.0651 - mean_absolute_error: 0.2133 \n",
      " 3/44 [=>............................] - ETA: 9s - loss: 0.0669 - mean_absolute_error: 0.2144 \n",
      " 4/44 [=>............................] - ETA: 13s - loss: 0.0685 - mean_absolute_error: 0.2177\n",
      " 8/44 [====>.........................] - ETA: 6s - loss: 0.0661 - mean_absolute_error: 0.2179\n",
      " 9/44 [=====>........................] - ETA: 5s - loss: 0.0666 - mean_absolute_error: 0.2181\n",
      "13/44 [=======>......................] - ETA: 3s - loss: 0.0688 - mean_absolute_error: 0.2213\n",
      "14/44 [========>.....................] - ETA: 3s - loss: 0.0721 - mean_absolute_error: 0.2263\n",
      "24/44 [===============>..............] - ETA: 1s - loss: 0.0807 - mean_absolute_error: 0.2418\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.0800 - mean_absolute_error: 0.2413\n",
      "26/44 [================>.............] - ETA: 1s - loss: 0.0803 - mean_absolute_error: 0.2424\n",
      "29/44 [==================>...........] - ETA: 1s - loss: 0.0814 - mean_absolute_error: 0.2420\n",
      "34/44 [======================>.......] - ETA: 0s - loss: 0.0800 - mean_absolute_error: 0.2409\n",
      "36/44 [=======================>......] - ETA: 0s - loss: 0.0810 - mean_absolute_error: 0.2422\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.0790 - mean_absolute_error: 0.2389\n",
      "44/44 [==============================] - 9s 80ms/step - loss: 0.0781 - mean_absolute_error: 0.2365\n",
      " 1/44 [..............................] - ETA: 3:47 - loss: 0.0228 - mean_absolute_error: 0.1156\n",
      " 2/44 [>.............................] - ETA: 21s - loss: 0.0279 - mean_absolute_error: 0.1283 \n",
      " 3/44 [=>............................] - ETA: 13s - loss: 0.1086 - mean_absolute_error: 0.2313\n",
      " 4/44 [=>............................] - ETA: 10s - loss: 0.1305 - mean_absolute_error: 0.2694\n",
      " 5/44 [==>...........................] - ETA: 9s - loss: 0.1285 - mean_absolute_error: 0.2685 \n",
      " 6/44 [===>..........................] - ETA: 8s - loss: 0.1103 - mean_absolute_error: 0.2426\n",
      " 9/44 [=====>........................] - ETA: 6s - loss: 0.0914 - mean_absolute_error: 0.2122\n",
      "11/44 [======>.......................] - ETA: 6s - loss: 0.0944 - mean_absolute_error: 0.2127\n",
      "13/44 [=======>......................] - ETA: 5s - loss: 0.1679 - mean_absolute_error: 0.2652\n",
      "15/44 [=========>....................] - ETA: 4s - loss: 0.1542 - mean_absolute_error: 0.2489\n",
      "24/44 [===============>..............] - ETA: 2s - loss: 0.1615 - mean_absolute_error: 0.2554\n",
      "34/44 [======================>.......] - ETA: 0s - loss: 0.1550 - mean_absolute_error: 0.2502\n",
      "39/44 [=========================>....] - ETA: 0s - loss: 0.1624 - mean_absolute_error: 0.2609\n",
      "44/44 [==============================] - 9s 80ms/step - loss: 0.1663 - mean_absolute_error: 0.2579\n",
      " 1/44 [..............................] - ETA: 3:52 - loss: 0.0626 - mean_absolute_error: 0.1680\n",
      " 2/44 [>.............................] - ETA: 12s - loss: 0.0671 - mean_absolute_error: 0.1932 \n",
      " 3/44 [=>............................] - ETA: 14s - loss: 0.2117 - mean_absolute_error: 0.3300\n",
      " 4/44 [=>............................] - ETA: 11s - loss: 0.3262 - mean_absolute_error: 0.4421\n",
      " 5/44 [==>...........................] - ETA: 12s - loss: 0.9958 - mean_absolute_error: 0.6144\n",
      " 6/44 [===>..........................] - ETA: 11s - loss: 0.8853 - mean_absolute_error: 0.5874\n",
      " 7/44 [===>..........................] - ETA: 11s - loss: 0.8309 - mean_absolute_error: 0.5789\n",
      "12/44 [=======>......................] - ETA: 5s - loss: 0.9510 - mean_absolute_error: 0.6669\n",
      "15/44 [=========>....................] - ETA: 4s - loss: 1.0008 - mean_absolute_error: 0.6975\n",
      "18/44 [===========>..................] - ETA: 3s - loss: 1.2601 - mean_absolute_error: 0.7403\n",
      "20/44 [============>.................] - ETA: 3s - loss: 1.6434 - mean_absolute_error: 0.8363\n",
      "24/44 [===============>..............] - ETA: 2s - loss: 1.9274 - mean_absolute_error: 0.8922\n",
      "28/44 [==================>...........] - ETA: 1s - loss: 2.0198 - mean_absolute_error: 0.9427\n",
      "34/44 [======================>.......] - ETA: 0s - loss: 2.4234 - mean_absolute_error: 1.0339\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 2.6620 - mean_absolute_error: 1.0865\n",
      "44/44 [==============================] - 9s 87ms/step - loss: 2.5970 - mean_absolute_error: 1.0763\n",
      " 1/43 [..............................] - ETA: 3:40 - loss: 1.7042 - mean_absolute_error: 0.6658\n",
      " 2/43 [>.............................] - ETA: 9s - loss: 1.8445 - mean_absolute_error: 0.7640  \n",
      " 3/43 [=>............................] - ETA: 12s - loss: 1.9127 - mean_absolute_error: 0.7876\n",
      " 4/43 [=>............................] - ETA: 11s - loss: 1.6670 - mean_absolute_error: 0.7294\n",
      " 5/43 [==>...........................] - ETA: 9s - loss: 1.5935 - mean_absolute_error: 0.7221 \n",
      " 6/43 [===>..........................] - ETA: 8s - loss: 1.3462 - mean_absolute_error: 0.6456\n",
      " 7/43 [===>..........................] - ETA: 7s - loss: 1.3718 - mean_absolute_error: 0.6639\n",
      " 9/43 [=====>........................] - ETA: 7s - loss: 1.2117 - mean_absolute_error: 0.6305\n",
      "10/43 [=====>........................] - ETA: 7s - loss: 1.4234 - mean_absolute_error: 0.6724\n",
      "14/43 [========>.....................] - ETA: 4s - loss: 1.3626 - mean_absolute_error: 0.6646\n",
      "19/43 [============>.................] - ETA: 2s - loss: 2.0357 - mean_absolute_error: 0.7628\n",
      "21/43 [=============>................] - ETA: 2s - loss: 2.1251 - mean_absolute_error: 0.7767\n",
      "22/43 [==============>...............] - ETA: 2s - loss: 2.1777 - mean_absolute_error: 0.7841\n",
      "27/43 [=================>............] - ETA: 1s - loss: 2.5397 - mean_absolute_error: 0.8279\n",
      "34/43 [======================>.......] - ETA: 0s - loss: 2.7920 - mean_absolute_error: 0.8665\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 3.1319 - mean_absolute_error: 0.9214\n",
      "43/43 [==============================] - 9s 89ms/step - loss: 3.2512 - mean_absolute_error: 0.9534\n",
      " 1/44 [..............................] - ETA: 3:45 - loss: 0.0750 - mean_absolute_error: 0.2197\n",
      " 2/44 [>.............................] - ETA: 15s - loss: 0.0807 - mean_absolute_error: 0.2450 \n",
      " 3/44 [=>............................] - ETA: 13s - loss: 0.0763 - mean_absolute_error: 0.2363\n",
      " 5/44 [==>...........................] - ETA: 9s - loss: 0.0649 - mean_absolute_error: 0.2147 \n",
      " 6/44 [===>..........................] - ETA: 10s - loss: 0.0745 - mean_absolute_error: 0.2314\n",
      " 9/44 [=====>........................] - ETA: 6s - loss: 0.0717 - mean_absolute_error: 0.2303\n",
      "13/44 [=======>......................] - ETA: 4s - loss: 0.0625 - mean_absolute_error: 0.2142\n",
      "15/44 [=========>....................] - ETA: 4s - loss: 0.0638 - mean_absolute_error: 0.2177\n",
      "21/44 [=============>................] - ETA: 2s - loss: 0.0587 - mean_absolute_error: 0.2077\n",
      "24/44 [===============>..............] - ETA: 2s - loss: 0.0599 - mean_absolute_error: 0.2095\n",
      "26/44 [================>.............] - ETA: 1s - loss: 0.0593 - mean_absolute_error: 0.2091\n",
      "36/44 [=======================>......] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.2064\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.0582 - mean_absolute_error: 0.2075\n",
      "44/44 [==============================] - 9s 85ms/step - loss: 0.0579 - mean_absolute_error: 0.2063\n",
      " 1/40 [..............................] - ETA: 3:11 - loss: 0.1437 - mean_absolute_error: 0.3582\n",
      " 2/40 [>.............................] - ETA: 14s - loss: 0.1259 - mean_absolute_error: 0.3218 \n",
      " 4/40 [==>...........................] - ETA: 7s - loss: 0.1427 - mean_absolute_error: 0.3359 \n",
      " 5/40 [==>...........................] - ETA: 6s - loss: 0.1298 - mean_absolute_error: 0.3166\n",
      " 7/40 [====>.........................] - ETA: 4s - loss: 0.1125 - mean_absolute_error: 0.2910\n",
      " 8/40 [=====>........................] - ETA: 4s - loss: 0.1174 - mean_absolute_error: 0.3002\n",
      "11/40 [=======>......................] - ETA: 4s - loss: 0.1086 - mean_absolute_error: 0.2883\n",
      "12/40 [========>.....................] - ETA: 3s - loss: 0.1076 - mean_absolute_error: 0.2873\n",
      "15/40 [==========>...................] - ETA: 2s - loss: 0.1043 - mean_absolute_error: 0.2834\n",
      "16/40 [===========>..................] - ETA: 3s - loss: 0.1012 - mean_absolute_error: 0.2791\n",
      "21/40 [==============>...............] - ETA: 1s - loss: 0.0984 - mean_absolute_error: 0.2759\n",
      "24/40 [=================>............] - ETA: 1s - loss: 0.0953 - mean_absolute_error: 0.2708\n",
      "28/40 [====================>.........] - ETA: 1s - loss: 0.0943 - mean_absolute_error: 0.2703\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.2690\n",
      "40/40 [==============================] - 9s 94ms/step - loss: 0.0930 - mean_absolute_error: 0.2695\n",
      " 1/44 [..............................] - ETA: 3:52 - loss: 4.3832 - mean_absolute_error: 1.6635\n",
      " 2/44 [>.............................] - ETA: 19s - loss: 3.0778 - mean_absolute_error: 1.3898 \n",
      " 4/44 [=>............................] - ETA: 9s - loss: 5.5890 - mean_absolute_error: 2.0182 \n",
      " 5/44 [==>...........................] - ETA: 7s - loss: 5.9376 - mean_absolute_error: 2.1054\n",
      " 9/44 [=====>........................] - ETA: 4s - loss: 4.9000 - mean_absolute_error: 1.8688\n",
      "12/44 [=======>......................] - ETA: 3s - loss: 4.8612 - mean_absolute_error: 1.8700\n",
      "13/44 [=======>......................] - ETA: 3s - loss: 5.3646 - mean_absolute_error: 1.9478\n",
      "16/44 [=========>....................] - ETA: 3s - loss: 5.2865 - mean_absolute_error: 1.9065\n",
      "18/44 [===========>..................] - ETA: 2s - loss: 5.5565 - mean_absolute_error: 1.9488\n",
      "19/44 [===========>..................] - ETA: 2s - loss: 5.8694 - mean_absolute_error: 1.9998\n",
      "21/44 [=============>................] - ETA: 2s - loss: 7.0709 - mean_absolute_error: 2.1479\n",
      "28/44 [==================>...........] - ETA: 1s - loss: 8.8500 - mean_absolute_error: 2.4256\n",
      "38/44 [========================>.....] - ETA: 0s - loss: 12.2872 - mean_absolute_error: 2.8637\n",
      "43/44 [============================>.] - ETA: 0s - loss: 12.3486 - mean_absolute_error: 2.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 9s 83ms/step - loss: 12.3505 - mean_absolute_error: 2.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:46:48,189 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011563008; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:46:58,218 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011182080; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:08,227 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011128832; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:18,313 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011100160; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:28,386 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011083776; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:38,470 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24011059200; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:48,563 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010575872; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:47:58,582 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010489856; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:08,671 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010432512; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:18,764 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010383360; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:28,848 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010366976; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:38,853 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24010301440; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:48,857 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24009371648; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:48:58,938 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24009105408; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:49:09,006 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24008863744; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:49:19,062 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24008089600; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:49:29,125 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24009904128; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-07-11 07:49:39,189 E 16453 1015981] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-11_06-27-28_838654_16427 is over 95% full, available space: 24009912320; capacity: 494384795648. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.5,  # Sample 10% of available clients for training\n",
    "    fraction_evaluate=0.1,  # Sample 5% of available clients for evaluation\n",
    "    min_fit_clients=40,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=10,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=int(\n",
    "        NUM_CLIENTS * 0.75\n",
    "    ),  # Wait until at least 75 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
    "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
    ")\n",
    "\n",
    "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
    "# client needs exclusive access to these many resources in order to run\n",
    "client_resources = {\"num_cpus\": 8.0}\n",
    "\n",
    "# Start simulation\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=get_client_fn(df_dataset),\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=10),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    "    actor_kwargs={\n",
    "            \"on_actor_init_fn\": enable_tf_gpu_growth  # Enable GPU growth upon actor init\n",
    "            # does nothing if `num_gpus` in client_resources is 0.0\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(f\"{history.metrics_centralized = }\")\n",
    "\n",
    "global_accuracy_centralised = history.metrics_distributed[\"accuracy\"]\n",
    "global_loss_centralised = history.losses_distributed\n",
    "rounds = [data[0] for data in global_accuracy_centralised]\n",
    "loss = [data[1] for data in global_loss_centralised]\n",
    "acc = [100.0 * data[1] for data in global_accuracy_centralised]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "                    subplot_titles=(\"MEAN ABSOLUTE ERROR\", \"MEAN SQUARED ERROR\"))\n",
    "\n",
    "# Add scatter plot for accuracy\n",
    "fig.add_trace(go.Scatter(x=rounds, y=acc, mode='markers', name='MAE'), row=1, col=1)\n",
    "# Add line plot for accuracy\n",
    "fig.add_trace(go.Scatter(x=rounds, y=acc, mode='lines', name='MAE Line'), row=1, col=1)\n",
    "\n",
    "# Add scatter plot for loss\n",
    "fig.add_trace(go.Scatter(x=rounds, y=loss, mode='markers', name='MSE'), row=2, col=1)\n",
    "# Add line plot for loss\n",
    "fig.add_trace(go.Scatter(x=rounds, y=loss, mode='lines', name='MSE Line'), row=2, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=800,  # Height of the figure\n",
    "    title_text=f\"SMART METERS - {NUM_CLIENTS} clients with {int(0.5 * NUM_CLIENTS)} sampled clients per round\",\n",
    ")\n",
    "\n",
    "# Update x-axis for all subplots\n",
    "fig.update_xaxes(title_text=\"Round\", row=2, col=1)\n",
    "# Update y-axis for each subplot\n",
    "fig.update_yaxes(title_text=\"MEAN ABSOLUTE ERROR\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"MEAN SQUARED ERROR\", row=2, col=1)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "flower.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
